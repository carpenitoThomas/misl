a_misl_imputations <- misl(dataset = nhanes,
m = 1,
maxit = 2,
cat_method = c("Lrnr_mean", "Lrnr_xgboost")
#con_method = c("Lrnr_mean", "Lrnr_glm", "Lrnr_gam", "Lrnr_svm", "Lrnr_ranger")
)
a_misl_imputations
a_misl_imputations <- misl(dataset = nhanes,
m = 1,
maxit = 5,
cat_method = c("Lrnr_mean", "Lrnr_xgboost")
#con_method = c("Lrnr_mean", "Lrnr_glm", "Lrnr_gam", "Lrnr_svm", "Lrnr_ranger")
)
a_misl_imputations
misl_imp <- misl(nhanes, m = 1)
misl_imp
colSums(is.na(nhanes))
colSums(is.na(misl_imp[[1]]))
load_all()
load()
library('devtools')
load_all()
m <- 1
maxit <- 2
# Identify which order the columns should be imputed.
# The order here specifies least missing data to most though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
dataset <- nhanes
# Identify which order the columns should be imputed.
# The order here specifies least missing data to most though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
column <- "Education"
if(!quiet){print(paste("Imputing:", column))}
quiet <- TRUE
quiet <- FALSE
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i_loop == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
i_loop <- 1
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i_loop == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
nrow(full_dataframe)
View*full_dataframe
View(full_dataframe)
# Next identify the predictors (xvars) and outcome (yvar) depending on the column imputing
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
yvar <- column
xvars
yvar
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
missing_default <- "mean"
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
View(full_dataframe)
# Specifying the outcome_type will be helpful for checking learners.
outcome_type <- check_datatype(dataset[[yvar]])
outcome_type
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glm")
cat_method = c("Lrnr_mean", "Lrnr_xgboost")
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
learners
cat_method
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(outcome_type == "binary"){
predicted_values <- stats::rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + stats::rnorm(n = length(predictions), mean = 0, sd = stats::sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <-  as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
}
View(dataset_master_copy)
as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
View(predictions)
predictions[953]
as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
missing_yvar
as.character(sl3::predict_classes(sl3::unpack_predictions(predictions)))
sl3::predict_classes(sl3::unpack_predictions(predictions))
sl3::unpack_predictions(predictions)
sl3::predict_classes(sl3::unpack_predictions(predictions))
?sl3::predict_classes
sl3::unpack_predictions(predictions))
sl3::unpack_predictions(predictions)
remotes::install_github("tlverse/sl3@v1.3.5")
remotes::install_github("tlverse/sl3@v1.3.5", force = TRUE)
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions
predictions[[1]]
sl3::predict_classes(sl3::unpack_predictions(predictions)))
sl3::predict_classes(sl3::unpack_predictions(predictions))
sl3::unpack_predictions(predictions))
sl3::unpack_predictions(predictions)
rowSums(sl3::unpack_predictions(predictions)))
rowSums(sl3::unpack_predictions(predictions))
predictions <- stack_fit$predict(new_prediction_task)
predictions
predictions[[1]]
get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
get(missing_default)(dataset_copy[[6]], na.rm = TRUE)
dataset_copy[[6]]
get(missing_default)(dataset_copy[[6]], na.rm = TRUE)
missing_default
get(mode)(dataset_copy[[6]], na.rm = TRUE)
?mode
get(impute_mode)(dataset_copy[[6]], na.rm = TRUE)
column_type
impute_mode(dataset_copy[[column_number]])
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
dataset_copy
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions[[1]]
stack_fit
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
dataset_copy
predictions <- stack_fit$predict(new_prediction_task)
predictions
predictions[[1]]
names(predictions[[1]][[1]])
new_prediction_task
stack_fit
sl
library('devtools')
load_all()
library("misl")
dataset <- nhanes
nrow(nhanes)
m = 1
maxit = 5
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glm")
cat_method = c("Lrnr_mean", "Lrnr_xgboost")
missing_default = "mean"
quiet = FALSE
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
# Identify which order the columns should be imputed.
# The order here specifies least missing data to most though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
column <- "Education"
if(!quiet){print(paste("Imputing:", column))}
i_loop <- 1
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i_loop == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
# Next identify the predictors (xvars) and outcome (yvar) depending on the column imputing
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
yvar <- column
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
colSums(is.na(full_dataframe))
# Specifying the outcome_type will be helpful for checking learners.
outcome_type <- check_datatype(dataset[[yvar]])
outcome_type
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
task
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
learners
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
stack_fit
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions
predictions[[1]]
learner_stack_code
stack
sl
stack_fit
?sl$train
?train
task
yvar
outcome_type
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar, outcome_type = outcome_type)
stack_fit <- sl$train(task)
stack_fit
?make_sl3_Task
?sl3::make_sl3_Task
outcome_type
str(full_dataframe)
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar, outcome_type = outcome_type)
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
stack_fit
sl3::sl3_list_learners("categorical")
sl3_list_learners("categorical")
sl3::sl3_list_learners("categorical")
sl3::sl3_list_learners("categorical")
sl3
sl3::sl3_list_learners("binomial")
sl3::sl3_list_learners("continuous")
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
new_prediction_task
predictions <- stack_fit$predict(new_prediction_task)
predictions[[1]]
as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))
)
build_all()
load_all()
library('misl')
# Specifying the outcome_type will be helpful for checking learners.
outcome_type <- check_datatype(dataset[[yvar]])
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions
predictions[[1]]
# Lastly, we should remove the learners for the next column (should there be overlap)
for(learner in learner_list){
code.lm <- paste("rm(", learner, ")", sep="")
eval(parse(text=code.lm))
}
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
task
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
stack
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
sl
sl3::sl3_list_learners("continuous")
sl3::sl3_list_learners("continuousasd")
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
new_prediction_task
str(dataset_copy)
View(dataset_copy)
predictions <- stack_fit$predict(new_prediction_task)
unpack_predictions
sl3::unpack_predictions(stack_fit$base_predict())
remotes::install_github("tlverse/sl3@v1.3.5")
remotes::install_github("tlverse/sl3")
library(sl3)
remove.packages("sl3")
remotes::install_github("tlverse/sl3")
load_all()
