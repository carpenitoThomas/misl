build_readme()
build_readme()
library(misl)
library(misl)
load_all()
library(misl)
misl_imp <- misl(nhanes, maxit = 2, m = 1, quiet = TRUE)
misl_modeling <- lapply(misl_imp, function(y){
stats::lm(TotChol ~ Age + Weight + Height + Smoke100 + Education, data = y)
})
summary(mice::pool(misl_modeling))
build_readme()
?build_readme
build_readme(quiet = FALSE)
build_readme(quiet = FALSE)
build_readme(quiet = FALSE)
load_all()
library(misl)
misl_imp <- misl(nhanes, maxit = 2, m = 2, quiet = FALSE)
misl_modeling <- lapply(misl_imp, function(y){
stats::lm(TotChol ~ Age + Weight + Height + Smoke100 + Education, data = y)
})
summary(mice::pool(misl_modeling))
misl_imp
View(misl_imp[[1]])
colSums(misl_imp[[1]])
colSums(is.na(misl_imp[[1]]))
load_all()
dataset <- nhanes
m = 5
maxit = 5
seed = NA
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glm")
cat_method = c("Lrnr_mean")
missing_default = "mean"
# Do users want to know which dataset they are imputing?
if(!quiet){print(paste("Imputing dataset:", m_loop))}
# Identify which order the columns should be imputed.
# The order here specifies most missing data to least though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
i <- 1
column_order
# Begin the iteration column by column
for(column in column_order[1:5]){
# Print what column we are starting with
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
outcome_type <- check_datatype(dataset[[yvar]])
# We should now have a complete dataframe and can being misl.
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# TODO: Add Screeners?
# Depending on the outcome, we need to build out the learner
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(outcome_type == "binary"){
predicted_values <- rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + rnorm(n = length(predictions), mean = 0, sd = sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <-  as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
}
# Lastly, we should remove the learners for the next column (should there be overlap)
for(learner in learner_list){
code.lm <- paste("rm(", learner, ")", sep="")
eval(parse(text=code.lm))
}
}
quiet <- FALSE
# Begin the iteration column by column
for(column in column_order[1:5]){
# Print what column we are starting with
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
outcome_type <- check_datatype(dataset[[yvar]])
# We should now have a complete dataframe and can being misl.
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# TODO: Add Screeners?
# Depending on the outcome, we need to build out the learner
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(outcome_type == "binary"){
predicted_values <- rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + rnorm(n = length(predictions), mean = 0, sd = sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <-  as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
}
# Lastly, we should remove the learners for the next column (should there be overlap)
for(learner in learner_list){
code.lm <- paste("rm(", learner, ")", sep="")
eval(parse(text=code.lm))
}
}
column <- "Education"
column_order
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
full_dataframe
colSums(is.na(full_dataframe))
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
outcome_type <- check_datatype(dataset[[yvar]])
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learner
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
dataset_copy <- dataset_master_copy
dataset_copy
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
dataset_copy
yvar
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
outcome_type
as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
predictions
as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))
)
predictions
predictions[[1]]
as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
missing_yvar
as.character(sl3::predict_classes(sl3::unpack_predictions(predictions)))
sl3::predict_classes(sl3::unpack_predictions(predictions))
(sl3::unpack_predictions(predictions)
)
sl3::unpack_predictions(predictions
)
sl3::predict_classes(sl3::unpack_predictions(predictions))
outcome_type
predictions
str(predictions)
?sl3::predict_classes
sl3::predict_classes(predictions)
sl3::unpack_predictions(predictions))
sl3::unpack_predictions(predictions)
sl3::unpack_predictions(predictions)
colnames(sl3::unpack_predictions(predictions))
colnames(predictions)
predictions
str(dataset_copy)
xvars
yvar
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions
outcome_type
as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
View(predictions)
stack_fit$predict(new_prediction_task)
str(dataset_copy)
View(dataset_copy)
predictions <- stack_fit$predict(new_prediction_task)
predictions
sl3::predict_classes(sl3::unpack_predictions(predictions))
predictions[[1]]
learner_stack_code
Lrnr_glmnet <- sl3::Lrnr_glmnet()$new
code.lm
Lrnr_glmnet <- sl3::Lrnr_glmnet$new()
learner_stack_code
stack <- sl3::make_learner(sl3::Stack,Lrnr_mean, Lrnr_glmnet)
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions[[1]]
build_all()
load_all()
check()
build_readme()
load_all()
library("devtools")
load_all()
misl_imp <- misl(nhanes, maxit = 2, m = 2, quiet = FALSE)
misl_imp
View(nhanes)
View(NHANES)
library(misl)
NHANES
load('data-raw/nhanes.rdata')
View(NHANES)
nhanes <- NHANES %>%
select(c(Age, Weight, Height, TotChol, Smoke100, Education)) %>%
mutate(Smoke100 = ifelse(Smoke100 == "No", 0, 1))
nhanes2 <- NHANES %>%
select(c(Age, Weight, Height, TotChol, Smoke100, Education)) %>%
mutate(Smoke100 = ifelse(Smoke100 == "No", 0, 1)) %>%
distinct
nrow(nhanes2)
nhanes2 <- NHANES %>%
select(c(ID, Age, Weight, Height, TotChol, Smoke100, Education)) %>%
mutate(Smoke100 = ifelse(Smoke100 == "No", 0, 1)) %>%
distinct
nrow(nhanes2)
nhanes2 <- NHANES %>%
select(c(ID, Age, Weight, Height, TotChol, Smoke100, Education)) %>%
mutate(Smoke100 = ifelse(Smoke100 == "No", 0, 1)) %>%
distinct %>%
select(-ID)
View(nhanes2)
load('data-raw/nhanes.rdata')
nhanes <- NHANES %>%
select(c(ID, Age, Weight, Height, TotChol, Smoke100, Education)) %>%
mutate(Smoke100 = ifelse(Smoke100 == "No", 0, 1)) %>%
distinct %>%
select(-ID)
write_csv(nhanes, "data-raw/nhanes.csv")
library(tidyverse)
library(readxl)
library(usethis)
load('data-raw/nhanes.rdata')
nhanes <- NHANES %>%
select(c(ID, Age, Weight, Height, TotChol, Smoke100, Education)) %>%
mutate(Smoke100 = ifelse(Smoke100 == "No", 0, 1)) %>%
distinct %>%
select(-ID)
write_csv(nhanes, "data-raw/nhanes.csv")
usethis::use_data(nhanes, overwrite = TRUE, compress = 'xz')
build_readme()
build_readme()
?mice
build_readme()
build_readme()
?mice
?sl3
sl3::sl3_list_learners("continuous")
sl3::sl3_list_properties("continuous")
sl3::sl3_list_learners("continuous")
sl3::sl3_list_learners("binary")
l3_list_learners(c("binomial", "offset"))
sl3_list_learners(c("binomial", "offset"))
sl3::sl3_list_learners(c("binomial", "offset"))
library(misl)
sl3::sl3_list_learners(c("binomial", "offset"))
sl3::sl3_list_learners(c("binomial", "offset"))
library("sl3")
sl3::sl3_list_learners(c("binomial", "offset"))
load_all()
sl3::sl3_list_learners(c("binomial", "offset"))
sl3::sl3_list_learners(c("binomial", "offset"))
load_all()
library("devtools")
load_all()
sl3::sl3_list_learners(c("binomial", "offset"))
list_learners <- function(...) sl3::sl3_list_learners()
list_learners("continuous")
list_learners(c("binomial", "offset"))
library("misl")
load_all()
load_all()
library("misl")
list_learners(c("binomial", "offset"))
load_all()
library("misl")
list_learners(c("binomial", "offset"))
sl3::sl3_list_learners(c("binomial", "offset"))
library("sl3")
sl3::sl3_list_learners(c("binomial", "offset"))
load_all()
library("devtools")
library(misl)
?list_learners
?misl
list_learners <- function(...) sl3::sl3_list_learners(...)
?list_learners
list_learners
?list_learners
misl::list_learners
misl::check_datatype
library("misl")
?misl
?check_datatype
?impute_mode
?impute_placeholders
load_all()
load_all()
?misl::list_learners()
misl::list_learners()
misl::list_learners("binary")
load_all()
library("misl")
misl::list_learners("binary")
sl3::sl3_list_learners("binary")
library("sl3")
sl3::sl3_list_learners("binary")
sl3::sl3_list_learners(c("binary"))
??sl3_list_learners
sl3_list_learners(c("binomial", "offset"))
sl3_list_learners("binomial")
load_all()
library("devtools")
load_all()
library('misl')
misl::list_learners()
?misl::list_learners()
?misl::list_learners("binomial")
?misl::list_learners("binary")
sl3_list_learners(c("binomial", "offset"))
misl::list_learners(c("binomial", "offset"))
?which
load_all()
use_package(sl3)
use_package("sl3")
list_learners <- function(...) sl3::sl3_list_learners(...)
list_learners("binary")
sl3::sl3_list_learners()
?sl3::sl3_list_learners()
library("sl3")
sl3_list_learners("binary")
sl3_list_learners("continuous")
sl3_list_learners("binomial")
