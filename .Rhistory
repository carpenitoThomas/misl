sl_sched_boot_dot <- delayed::Scheduler$new(sl_train_boot_dot, delayed::FutureJob)
sl_stack_fit_boot_dot <- sl_sched_boot_dot$compute()
# We are now at the point where we can obtain predictions for matching candidates using X_miss
# Here we can create the predictions and then we can match them with the hot-deck method
# Interestingly, there are 4 different ways we can match: https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# Original PMM uses type 1 matching, so that's what we are going to use
predictions_task_boot_dot <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
predictions_boot_dot <- sl_stack_fit_boot_dot$predict(predictions_task_boot_dot)
if(outcome_type == "continuous"){
sl_train_full_hat <- sl3::delayed_learner_train(sl, sl3_task_full_hat)
sl_sched_full_hat <- delayed::Scheduler$new(sl_train_full_hat, delayed::FutureJob)
sl_stack_fit_full_hat <- sl_sched_full_hat$compute()
predictions_task_full_hat <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
predictions_full_hat <- sl_stack_fit_full_hat$predict(predictions_task_full_hat)
}
if(outcome_type == "binomial"){
# Imputation for binary variables can be found from the following resources:
# https://stefvanbuuren.name/fimd/sec-categorical.html#def:binary
# https://github.com/cran/mice/blob/master/R/mice.impute.logreg.R
uniform_values <- runif(length(predictions_boot_dot))
predicted_values <- as.integer(uniform_values <= predictions_boot_dot)
dataset_master_copy[[column]] <- ifelse(is.na(dataset[[column]]), predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
predictions_boot_dot <- predictions_boot_dot
# If continuous, we can do matching
# Find the 5 closest donors and making a random draw from them - there are a lot of ways to do matching
# https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# This matching was updated on 10/4 to help with speedup (15% reduction in time). We only match on missing values.
list_of_matches <- c()
non_na_predictions <- predictions_boot_dot[!ry]
for(value in seq_along(non_na_predictions)){
distance <- head(order(abs(non_na_predictions[value] - predictions_full_hat[ry])), 5)
list_of_matches[value] <- y[ry][sample(distance,1)]
}
list_of_matches
}else if(outcome_type== "categorical"){
# For categorical data we follow advice suggested by Van Buuren:
# https://github.com/cran/mice/blob/master/R/mice.impute.polyreg.R
uniform_values <- rep(runif(length(predictions_boot_dot)), each = length(levels(y[ry])))
post <- sl3::unpack_predictions(predictions_boot_dot)
draws <- uniform_values > apply(post, 1, cumsum)
idx <- 1 + apply(draws, 2, sum)
predicted_values <- levels(fy)[idx]
#factor(predicted_values, levels = levels(fy))
levels(fy)[predicted_values]
}
}
mice_misl <- mice(boys_temp, method = c("misl"), maxit = 1, m = 1)
traceback()
levels = levels(fy)
#' r <- stats::complete.cases(boys[, xname])
#' x <- boys[r, xname]
#' y <- boys[r, "tv"]
#' ry <- !is.na(y)
#'
#' yimp <- mice.impute.misl(y, ry, x)
#'
#'  # This method can also be incorporated into the default mice method as well
#'  mice(boys, method = c("misl"))
#' @export
mice.impute.misl <- function(y, ry, x, wy = NULL,
con_method = c("Lrnr_glm_fast", "Lrnr_earth", "Lrnr_ranger"),
bin_method = c("Lrnr_earth", "Lrnr_glm_fast", "Lrnr_ranger"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_ranger"),
...) {
xobs <- data.frame(x[ry, , drop = FALSE])
xmis <- data.frame(x[wy, , drop = FALSE])
yobs <- y[ry]
xobsyobs <- cbind(xobs,yobs)
dataset_copy <- cbind(x, yobs = y)
dataset_copy <- as.data.frame(dataset_copy)
# Avoiding complications with variance estimates of the ensemble by using bootstrapping
bootstrap_sample <- dplyr::sample_n(xobsyobs, size = nrow(xobs), replace = TRUE)
# Checking the datatype for the super learner
outcome_type <- check_datatype(yobs)
xvars <- colnames(xobs)
colnames(dataset_copy) <- c(xvars, "yobs" )
# First, define the task using our bootstrap_sample (this helps with variability in imputations) and our full_dataframe sample
sl3_task_boot_dot <- sl3::make_sl3_Task(bootstrap_sample, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
sl3_task_full_hat <- sl3::make_sl3_Task(xobsyobs, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binomial = bin_method ,
continuous = con_method)
# If after drawing a bootstrap sample, any of the columns DO NOT contain the same factors as in the original data, then the algorithm will fail
# This is set up by design becuase the super learner cannot make out of sample predictions and the meta-learner will not know how
# to deal with the different factor levels. Should this happen, we will print a message to the user letting them know that the machine learning algorithms could NOT be used
# in this instance and instead for this iteration they must rely on the mean and a series of independent binomial samples. This will be updated should more learners become available.
if(outcome_type == "categorical"){
fy <- as.factor(y)
re_assign_cat_learners <- FALSE
for(column_number in seq_along(bootstrap_sample)){
if(is.factor(bootstrap_sample[[column_number]])){
if(length(levels(droplevels(bootstrap_sample)[[column_number]])) != length(levels(bootstrap_sample[[column_number]]))){
re_assign_cat_learners <- TRUE
}
}
}
if(re_assign_cat_learners){
warning("Factor levels are not compatible between bootstrap and original dataframes. This occurs as a product of bootstrap sampling. Lrnr_mean and Lrnr_independent_binomial have been subsituted for this iteration.")
learners <- c("Lrnr_mean", "Lrnr_independent_binomial")
}
}
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
# We can then go ahead and train our model on the bootstrap data
sl_train_boot_dot <- sl3::delayed_learner_train(sl, sl3_task_boot_dot)
# We can finally execute the super learner
# This bit of code can be used if people wanted multi-threading (depending on computer capacity)
sl_sched_boot_dot <- delayed::Scheduler$new(sl_train_boot_dot, delayed::FutureJob)
sl_stack_fit_boot_dot <- sl_sched_boot_dot$compute()
# We are now at the point where we can obtain predictions for matching candidates using X_miss
# Here we can create the predictions and then we can match them with the hot-deck method
# Interestingly, there are 4 different ways we can match: https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# Original PMM uses type 1 matching, so that's what we are going to use
predictions_task_boot_dot <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
predictions_boot_dot <- sl_stack_fit_boot_dot$predict(predictions_task_boot_dot)
if(outcome_type == "continuous"){
sl_train_full_hat <- sl3::delayed_learner_train(sl, sl3_task_full_hat)
sl_sched_full_hat <- delayed::Scheduler$new(sl_train_full_hat, delayed::FutureJob)
sl_stack_fit_full_hat <- sl_sched_full_hat$compute()
predictions_task_full_hat <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
predictions_full_hat <- sl_stack_fit_full_hat$predict(predictions_task_full_hat)
}
if(outcome_type == "binomial"){
# Imputation for binary variables can be found from the following resources:
# https://stefvanbuuren.name/fimd/sec-categorical.html#def:binary
# https://github.com/cran/mice/blob/master/R/mice.impute.logreg.R
uniform_values <- runif(length(predictions_boot_dot))
predicted_values <- as.integer(uniform_values <= predictions_boot_dot)
dataset_master_copy[[column]] <- ifelse(is.na(dataset[[column]]), predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
predictions_boot_dot <- predictions_boot_dot
# If continuous, we can do matching
# Find the 5 closest donors and making a random draw from them - there are a lot of ways to do matching
# https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# This matching was updated on 10/4 to help with speedup (15% reduction in time). We only match on missing values.
list_of_matches <- c()
non_na_predictions <- predictions_boot_dot[!ry]
for(value in seq_along(non_na_predictions)){
distance <- head(order(abs(non_na_predictions[value] - predictions_full_hat[ry])), 5)
list_of_matches[value] <- y[ry][sample(distance,1)]
}
list_of_matches
}else if(outcome_type== "categorical"){
# For categorical data we follow advice suggested by Van Buuren:
# https://github.com/cran/mice/blob/master/R/mice.impute.polyreg.R
uniform_values <- rep(runif(length(predictions_boot_dot)), each = length(levels(y[ry])))
post <- sl3::unpack_predictions(predictions_boot_dot)
draws <- uniform_values > apply(post, 1, cumsum)
idx <- 1 + apply(draws, 2, sum)
predicted_values <- levels(fy)[idx]
factor(predicted_values, levels = levels(fy))
}
}
#' r <- stats::complete.cases(boys[, xname])
#' x <- boys[r, xname]
#' y <- boys[r, "tv"]
#' ry <- !is.na(y)
#'
#' yimp <- mice.impute.misl(y, ry, x)
#'
#'  # This method can also be incorporated into the default mice method as well
#'  mice(boys, method = c("misl"))
#' @export
mice.impute.misl <- function(y, ry, x, wy = NULL,
con_method = c("Lrnr_glm_fast", "Lrnr_earth", "Lrnr_ranger"),
bin_method = c("Lrnr_earth", "Lrnr_glm_fast", "Lrnr_ranger"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_ranger"),
...) {
xobs <- data.frame(x[ry, , drop = FALSE])
xmis <- data.frame(x[wy, , drop = FALSE])
yobs <- y[ry]
xobsyobs <- cbind(xobs,yobs)
dataset_copy <- cbind(x, yobs = y)
dataset_copy <- as.data.frame(dataset_copy)
# Avoiding complications with variance estimates of the ensemble by using bootstrapping
bootstrap_sample <- dplyr::sample_n(xobsyobs, size = nrow(xobs), replace = TRUE)
# Checking the datatype for the super learner
outcome_type <- check_datatype(yobs)
xvars <- colnames(xobs)
colnames(dataset_copy) <- c(xvars, "yobs" )
# First, define the task using our bootstrap_sample (this helps with variability in imputations) and our full_dataframe sample
sl3_task_boot_dot <- sl3::make_sl3_Task(bootstrap_sample, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
sl3_task_full_hat <- sl3::make_sl3_Task(xobsyobs, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binomial = bin_method ,
continuous = con_method)
# If after drawing a bootstrap sample, any of the columns DO NOT contain the same factors as in the original data, then the algorithm will fail
# This is set up by design becuase the super learner cannot make out of sample predictions and the meta-learner will not know how
# to deal with the different factor levels. Should this happen, we will print a message to the user letting them know that the machine learning algorithms could NOT be used
# in this instance and instead for this iteration they must rely on the mean and a series of independent binomial samples. This will be updated should more learners become available.
if(outcome_type == "categorical"){
fy <- as.factor(y)
re_assign_cat_learners <- FALSE
for(column_number in seq_along(bootstrap_sample)){
if(is.factor(bootstrap_sample[[column_number]])){
if(length(levels(droplevels(bootstrap_sample)[[column_number]])) != length(levels(bootstrap_sample[[column_number]]))){
re_assign_cat_learners <- TRUE
}
}
}
if(re_assign_cat_learners){
warning("Factor levels are not compatible between bootstrap and original dataframes. This occurs as a product of bootstrap sampling. Lrnr_mean and Lrnr_independent_binomial have been subsituted for this iteration.")
learners <- c("Lrnr_mean", "Lrnr_independent_binomial")
}
}
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
# We can then go ahead and train our model on the bootstrap data
sl_train_boot_dot <- sl3::delayed_learner_train(sl, sl3_task_boot_dot)
# We can finally execute the super learner
# This bit of code can be used if people wanted multi-threading (depending on computer capacity)
sl_sched_boot_dot <- delayed::Scheduler$new(sl_train_boot_dot, delayed::FutureJob)
sl_stack_fit_boot_dot <- sl_sched_boot_dot$compute()
# We are now at the point where we can obtain predictions for matching candidates using X_miss
# Here we can create the predictions and then we can match them with the hot-deck method
# Interestingly, there are 4 different ways we can match: https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# Original PMM uses type 1 matching, so that's what we are going to use
predictions_task_boot_dot <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
predictions_boot_dot <- sl_stack_fit_boot_dot$predict(predictions_task_boot_dot)
if(outcome_type == "continuous"){
sl_train_full_hat <- sl3::delayed_learner_train(sl, sl3_task_full_hat)
sl_sched_full_hat <- delayed::Scheduler$new(sl_train_full_hat, delayed::FutureJob)
sl_stack_fit_full_hat <- sl_sched_full_hat$compute()
predictions_task_full_hat <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
predictions_full_hat <- sl_stack_fit_full_hat$predict(predictions_task_full_hat)
}
if(outcome_type == "binomial"){
# Imputation for binary variables can be found from the following resources:
# https://stefvanbuuren.name/fimd/sec-categorical.html#def:binary
# https://github.com/cran/mice/blob/master/R/mice.impute.logreg.R
uniform_values <- runif(length(predictions_boot_dot))
predicted_values <- as.integer(uniform_values <= predictions_boot_dot)
dataset_master_copy[[column]] <- ifelse(is.na(dataset[[column]]), predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
predictions_boot_dot <- predictions_boot_dot
# If continuous, we can do matching
# Find the 5 closest donors and making a random draw from them - there are a lot of ways to do matching
# https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# This matching was updated on 10/4 to help with speedup (15% reduction in time). We only match on missing values.
list_of_matches <- c()
non_na_predictions <- predictions_boot_dot[!ry]
for(value in seq_along(non_na_predictions)){
distance <- head(order(abs(non_na_predictions[value] - predictions_full_hat[ry])), 5)
list_of_matches[value] <- y[ry][sample(distance,1)]
}
list_of_matches
}else if(outcome_type== "categorical"){
# For categorical data we follow advice suggested by Van Buuren:
# https://github.com/cran/mice/blob/master/R/mice.impute.polyreg.R
uniform_values <- rep(runif(length(predictions_boot_dot)), each = length(levels(fy)))
post <- sl3::unpack_predictions(predictions_boot_dot)
draws <- uniform_values > apply(post, 1, cumsum)
idx <- 1 + apply(draws, 2, sum)
predicted_values <- levels(fy)[idx]
factor(predicted_values, levels = levels(fy))
}
}
mice_misl <- mice(boys_temp, method = c("misl"), maxit = 1, m = 1)
traceback()
str(boys_temp)
#' r <- stats::complete.cases(boys[, xname])
#' x <- boys[r, xname]
#' y <- boys[r, "tv"]
#' ry <- !is.na(y)
#'
#' yimp <- mice.impute.misl(y, ry, x)
#'
#'  # This method can also be incorporated into the default mice method as well
#'  mice(boys, method = c("misl"))
#' @export
mice.impute.misl <- function(y, ry, x, wy = NULL,
con_method = c("Lrnr_glm_fast", "Lrnr_earth", "Lrnr_ranger"),
bin_method = c("Lrnr_earth", "Lrnr_glm_fast", "Lrnr_ranger"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_ranger"),
...) {
xobs <- data.frame(x[ry, , drop = FALSE])
xmis <- data.frame(x[wy, , drop = FALSE])
yobs <- y[ry]
xobsyobs <- cbind(xobs,yobs)
dataset_copy <- cbind(x, yobs = y)
dataset_copy <- as.data.frame(dataset_copy)
# Avoiding complications with variance estimates of the ensemble by using bootstrapping
bootstrap_sample <- dplyr::sample_n(xobsyobs, size = nrow(xobs), replace = TRUE)
# Checking the datatype for the super learner
outcome_type <- check_datatype(yobs)
xvars <- colnames(xobs)
colnames(dataset_copy) <- c(xvars, "yobs" )
# First, define the task using our bootstrap_sample (this helps with variability in imputations) and our full_dataframe sample
sl3_task_boot_dot <- sl3::make_sl3_Task(bootstrap_sample, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
sl3_task_full_hat <- sl3::make_sl3_Task(xobsyobs, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binomial = bin_method ,
continuous = con_method)
# If after drawing a bootstrap sample, any of the columns DO NOT contain the same factors as in the original data, then the algorithm will fail
# This is set up by design becuase the super learner cannot make out of sample predictions and the meta-learner will not know how
# to deal with the different factor levels. Should this happen, we will print a message to the user letting them know that the machine learning algorithms could NOT be used
# in this instance and instead for this iteration they must rely on the mean and a series of independent binomial samples. This will be updated should more learners become available.
if(outcome_type == "categorical"){
fy <- as.factor(y)
re_assign_cat_learners <- FALSE
for(column_number in seq_along(bootstrap_sample)){
if(is.factor(bootstrap_sample[[column_number]])){
if(length(levels(droplevels(bootstrap_sample)[[column_number]])) != length(levels(bootstrap_sample[[column_number]]))){
re_assign_cat_learners <- TRUE
}
}
}
if(re_assign_cat_learners){
warning("Factor levels are not compatible between bootstrap and original dataframes. This occurs as a product of bootstrap sampling. Lrnr_mean and Lrnr_independent_binomial have been subsituted for this iteration.")
learners <- c("Lrnr_mean", "Lrnr_independent_binomial")
}
}
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
# We can then go ahead and train our model on the bootstrap data
sl_train_boot_dot <- sl3::delayed_learner_train(sl, sl3_task_boot_dot)
# We can finally execute the super learner
# This bit of code can be used if people wanted multi-threading (depending on computer capacity)
sl_sched_boot_dot <- delayed::Scheduler$new(sl_train_boot_dot, delayed::FutureJob)
sl_stack_fit_boot_dot <- sl_sched_boot_dot$compute()
# We are now at the point where we can obtain predictions for matching candidates using X_miss
# Here we can create the predictions and then we can match them with the hot-deck method
# Interestingly, there are 4 different ways we can match: https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# Original PMM uses type 1 matching, so that's what we are going to use
predictions_task_boot_dot <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
predictions_boot_dot <- sl_stack_fit_boot_dot$predict(predictions_task_boot_dot)
if(outcome_type == "continuous"){
sl_train_full_hat <- sl3::delayed_learner_train(sl, sl3_task_full_hat)
sl_sched_full_hat <- delayed::Scheduler$new(sl_train_full_hat, delayed::FutureJob)
sl_stack_fit_full_hat <- sl_sched_full_hat$compute()
predictions_task_full_hat <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = "yobs", outcome_type = outcome_type )
predictions_full_hat <- sl_stack_fit_full_hat$predict(predictions_task_full_hat)
}
if(outcome_type == "binomial"){
# Imputation for binary variables can be found from the following resources:
# https://stefvanbuuren.name/fimd/sec-categorical.html#def:binary
# https://github.com/cran/mice/blob/master/R/mice.impute.logreg.R
uniform_values <- runif(length(predictions_boot_dot))
predicted_values <- as.integer(uniform_values <= predictions_boot_dot)
dataset_master_copy[[column]] <- ifelse(is.na(dataset[[column]]), predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
predictions_boot_dot <- predictions_boot_dot
# If continuous, we can do matching
# Find the 5 closest donors and making a random draw from them - there are a lot of ways to do matching
# https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# This matching was updated on 10/4 to help with speedup (15% reduction in time). We only match on missing values.
list_of_matches <- c()
non_na_predictions <- predictions_boot_dot[!ry]
for(value in seq_along(non_na_predictions)){
distance <- head(order(abs(non_na_predictions[value] - predictions_full_hat[ry])), 5)
list_of_matches[value] <- y[ry][sample(distance,1)]
}
list_of_matches
}else if(outcome_type== "categorical"){
# For categorical data we follow advice suggested by Van Buuren:
# https://github.com/cran/mice/blob/master/R/mice.impute.polyreg.R
uniform_values <- rep(runif(length(predictions_boot_dot)), each = length(levels(fy)))
post <- sl3::unpack_predictions(predictions_boot_dot)
draws <- uniform_values > apply(post, 1, cumsum)
idx <- 1 + apply(draws, 2, sum)
predicted_values <- levels(fy)[idx]
factor(predicted_values[!ry], levels = levels(fy))
}
}
mice_misl <- mice(boys_temp, method = c("misl"), maxit = 1, m = 1)
set.seed(1234)
mice_misl <- mice(boys, method = c("misl"), maxit = 1, m = 1)
set.seed(1234)
misl_misl <- misl(boys, maxit = 2, m = 2, quiet = FALSE,
con_method = c("Lrnr_glm_fast", "Lrnr_earth", "Lrnr_ranger"),
bin_method = c("Lrnr_earth", "Lrnr_glm_fast", "Lrnr_ranger"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_ranger"))
mice_misl <- mice(boys, method = c("misl"), maxit = 2, m = 2)
colSums(is.na(dataset))
library("tidyverse")
library("tidyverse")
library("mice")
library("miceadds")
library("mitools")
library("srvyr")
library("misl")
library("survey")
#library("ggpubr")
#library("nnet")
set.seed(1234)
# Load the dataset
load("/Users/thomascarpenito/Documents/Northeastern/Dissertation/Firearm/data/fiss/ICPSR_38089/DS0001/fiss.rda")
fiss <- da38089.0001
fiss <- fiss %>%
filter(FA_GSW == "(1) Yes")
fiss_reduced <- fiss %>%
select(c(PSU, STRATUM, WT_C, YEAR,
ARG, CRIME, DRUGS, FIGHT, ONTHEJOB, BDYPTG_C, SEX, FIRARM_C, LOCG_C, TRANSG_C, WHOG_C, DIAG, DISP, AGENYR_C,
CLASS_C)) %>%
mutate(
CLASS_C = as.character(CLASS_C),
CLASS_C = ifelse(CLASS_C == "(1) Unintentnl", "Unintentional", CLASS_C),
CLASS_C = ifelse(CLASS_C == "(3) Suicide", "Self-Harm", CLASS_C),
CLASS_C = ifelse(CLASS_C == "(2) Assault", "Assault", CLASS_C),
CLASS_C = ifelse(CLASS_C == "(4) Law enforce", "Legal Intervention", CLASS_C),
CLASS_C = ifelse(CLASS_C == "(0) Unknown", "Undetermined", CLASS_C),
CLASS_C = factor(CLASS_C, levels = c("Assault","Unintentional", "Self-Harm", "Legal Intervention")),
age_cat = case_when(
AGENYR_C <= 14 ~ "Less than 14",
AGENYR_C >= 15 & AGENYR_C <= 34 ~ "Between 15 and 34",
AGENYR_C >= 35 & AGENYR_C <= 54 ~ "Between 35 and 54",
AGENYR_C >= 55~ "Greater than 55",
),
age_cat = factor(age_cat),
short_longgun = as.character(FIRARM_C),
short_longgun = ifelse(short_longgun == "(1) Handgun", "Handgun", "Long Gun"),
short_longgun = ifelse(FIRARM_C == "(0) Unknown", NA, short_longgun),
short_longgun = factor(short_longgun)
) %>%
mutate_if(is.factor, ~as.character(.)) %>%
mutate(across(where(is.character), ~na_if(., "(0) Unknown"))) %>%
mutate_if(is.character, ~as.factor(.))
colSums(is.na(fiss_reduced))
load("/Users/thomascarpenito/Documents/Northeastern/Dissertation/Pesticides/data/merged_analyte_hsd_wide.Rdata")
View(merged_analyte_hsd_wide)
load("/Users/thomascarpenito/Documents/Northeastern/Dissertation/Pesticides/data/merged_analyte_hsd_wide.Rdata")
dataset <- merged_analyte_hsd_wide
m = 5
maxit = 5
con_method = c("Lrnr_mean", "Lrnr_glm_fast")
bin_method = c("Lrnr_mean", "Lrnr_glm_fast")
cat_method = c("Lrnr_mean")
ignore_predictors = c("motherID", "pretermBirth", "race")
quiet = FALSE
# TODO: Builds out more checks to ensure the MISL algorithm can run properly
check_dataset(dataset)
library('devtools')
load_all()
# TODO: Builds out more checks to ensure the MISL algorithm can run properly
check_dataset(dataset)
# Initialize the return object (or, the dataframes that we want to return)
imputed_datasets <- vector("list", m)
# Initializes the trace plot (for inspection of imputations)
trace_plot <- expand.grid(statistic = c("mean", "sd"), value = NA, variable = colnames(dataset), m = m_loop, iteration = seq_along(1:maxit))
m_loop <- 1
# Initializes the trace plot (for inspection of imputations)
trace_plot <- expand.grid(statistic = c("mean", "sd"), value = NA, variable = colnames(dataset), m = m_loop, iteration = seq_along(1:maxit))
# Identifies which columns need to be imputed. According to van Buren, this order does not matter
# https://stefvanbuuren.name/fimd/sec-algoptions.html
# Future work should explore if this makes a difference
column_order <- sample(colnames(dataset)[colSums(is.na(dataset))!=0])
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
# As with all gibbs sampling methods, we will need to initialize the starting dataframe
# This is step 2 of https://stefvanbuuren.name/fimd/sec-FCS.html#def:mice
for(column_number in seq_along(dataset_master_copy)){
dataset_master_copy[is.na(dataset_master_copy[[column_number]]), column_number] <-  sample(dataset[[column_number]][!is.na(dataset[[column_number]])], sum(is.na(dataset[[column_number]])), replace = TRUE)
}
seq_along(dataset_master_copy)
column_number <- 1
dataset_master_copy[is.na(dataset_master_copy[[column_number]]), column_number]
sample(dataset[[column_number]][!is.na(dataset[[column_number]])], sum(is.na(dataset[[column_number]])), replace = TRUE)
# As with all gibbs sampling methods, we will need to initialize the starting dataframe
# This is step 2 of https://stefvanbuuren.name/fimd/sec-FCS.html#def:mice
for(column_number in seq_along(dataset_master_copy)){
print(column_number)
dataset_master_copy[is.na(dataset_master_copy[[column_number]]), column_number] <-  sample(dataset[[column_number]][!is.na(dataset[[column_number]])], sum(is.na(dataset[[column_number]])), replace = TRUE)
}
column_number <- 75
seq_along(dataset_master_copy)
dataset_master_copy[is.na(dataset_master_copy[[column_number]]), column_number]
library('sl3')
citation("sl3")
?sl3
?"sl3"
30/25
install.packages("hexSticker")
?sticker
library("hexSticker")
?sticker
