sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
new_prediction_task
str(dataset_copy)
View(dataset_copy)
predictions <- stack_fit$predict(new_prediction_task)
unpack_predictions
sl3::unpack_predictions(stack_fit$base_predict())
remotes::install_github("tlverse/sl3@v1.3.5")
remotes::install_github("tlverse/sl3")
library(sl3)
remove.packages("sl3")
remotes::install_github("tlverse/sl3")
load_all()
load_all()
library('devtools')
load_all()
library('misl')
dataset <- nhanes
m <- 1
maxit = 5
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glm")
cat_method = c("Lrnr_mean", "Lrnr_xgboost")
missing_default = "mean",
quiet = FALSE
missing_default = "mean"
quiet = FALSE
# Identify which order the columns should be imputed.
# The order here specifies least missing data to most though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
i_loop <- 1
column <- "Education"
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i_loop == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
# Next identify the predictors (xvars) and outcome (yvar) depending on the column imputing
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
yvar <- column
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
# Specifying the outcome_type will be helpful for checking learners.
outcome_type <- check_datatype(dataset[[yvar]])
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions[[1]]
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(outcome_type == "binary"){
predicted_values <- stats::rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + stats::rnorm(n = length(predictions), mean = 0, sd = stats::sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <-  as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
}
dataset_master_copy
library(tidyverse)
data(cpp)
cpp <- cpp %>%
select(c(bmi, agedays, feeding)) %>%
mutate(feeding = as.factor(feeding)) %>%
na.omit
task <- make_sl3_Task(cpp, covariates = c("agedays", "bmi"), outcome = "feeding")
Lrnr_mean <- Lrnr_mean$new()
stack <- make_learner(Stack, Lrnr_mean)
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
predictions <- stack_fit$predict()
names(predictions[[1]][[1]])
library(tidyverse)
data(cpp)
cpp <- cpp %>%
select(c(bmi, agedays, feeding)) %>%
mutate(feeding = as.factor(feeding)) %>%
na.omit
task <- make_sl3_Task(cpp, covariates = c("agedays", "bmi"), outcome = "feeding")
Lrnr_mean <- Lrnr_mean$new()
stack <- make_learner(Stack, Lrnr_mean)
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
predictions <- stack_fit$predict()
names(predictions[[1]][[1]])
library(sl3)
library(tidyverse)
data(cpp)
cpp <- cpp %>%
select(c(bmi, agedays, feeding)) %>%
mutate(feeding = as.factor(feeding)) %>%
na.omit
task <- make_sl3_Task(cpp, covariates = c("agedays", "bmi"), outcome = "feeding")
Lrnr_mean <- Lrnr_mean$new()
stack <- make_learner(Stack, Lrnr_mean)
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
predictions <- stack_fit$predict()
names(predictions[[1]][[1]])
Lrnr_glmnet <- Lrnr_glmnet$new()
stack2 <- make_learner(Stack, Lrnr_mean, Lrnr_glmnet)
sl2 <- sl3::Lrnr_sl$new(learners = stack2)
stack_fit2 <- sl2$train(task)
predictions2 <- stack_fit2$predict()
names(predictions2[[1]][[1]])
load_all()
sl3::sl3_list_learners("continuous")
library('misl')
sl3::sl3_list_learners("continuous")
dataset <- nhanes
m = 1
maxit = 5
seed = NA
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glm")
cat_method = c("Lrnr_mean", "Lrnr_xgboost")
missing_default = "mean"
quiet = FALSE
# Identify which order the columns should be imputed.
# The order here specifies least missing data to most though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
column <- "Education"
sl3::sl3_list_learners("continuous")
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i_loop == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
i_loop <- 1
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i_loop == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset_master_copy[!is.na(dataset_master_copy[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- dataset_master_copy
}
# Next identify the predictors (xvars) and outcome (yvar) depending on the column imputing
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
yvar <- column
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
# Specifying the outcome_type will be helpful for checking learners.
outcome_type <- check_datatype(dataset[[yvar]])
sl3::sl3_list_learners("continuous")
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
sl3::sl3_list_learners("continuous")
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
sl3::sl3_list_learners("continuous")
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
sl3::sl3_list_learners("continuous")
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
sl3::sl3_list_learners("continuous")
eval(parse(text=learner_stack_code))
sl3::sl3_list_learners("continuous")
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
sl3::sl3_list_learners("continuous")
stack_fit <- sl$train(task)
sl3::sl3_list_learners("continuous")
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
sl3::sl3_list_learners("continuous")
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
sl3::sl3_list_learners("continuous")
predictions <- stack_fit$predict(new_prediction_task)
sl3::sl3_list_learners("continuous")
predictions[[1]]
outcome_type
sl3::predict_classes(sl3::unpack_predictions(predictions))
sl3::unpack_predictions(predictions)
cat_method = c("Lrnr_mean", "Lrnr_glmnet")
# Lastly, we should remove the learners for the next column (should there be overlap)
for(learner in learner_list){
code.lm <- paste("rm(", learner, ")", sep="")
eval(parse(text=code.lm))
}
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
####### CAN I KEEP JUST THE FOLLOWING CODE AND REMOVE THE ELSE CONDITIONAL?
# And finally obtain predictions from the stack on the updated dataset
if(i_loop == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions[[1]]
a_misl_imputations <- misl(dataset = nhanes,
m = 1,
maxit = 5,
#con_method = c("Lrnr_mean", "Lrnr_glm", "Lrnr_gam", "Lrnr_svm", "Lrnr_ranger"),
bin_method = c("Lrnr_mean", "Lrnr_glm", "Lrnr_earth"),
#cat_method = c("Lrnr_mean", "Lrnr_glmnet")
)
install.packages("earth")
install.packages("earth")
a_misl_imputations <- misl(dataset = nhanes,
m = 1,
maxit = 5,
#con_method = c("Lrnr_mean", "Lrnr_glm", "Lrnr_gam", "Lrnr_svm", "Lrnr_ranger"),
bin_method = c("Lrnr_mean", "Lrnr_glm", "Lrnr_earth"),
#cat_method = c("Lrnr_mean", "Lrnr_glmnet")
)
library(earth)
a_misl_imputations <- misl(dataset = nhanes,
m = 1,
maxit = 5,
#con_method = c("Lrnr_mean", "Lrnr_glm", "Lrnr_gam", "Lrnr_svm", "Lrnr_ranger"),
bin_method = c("Lrnr_mean", "Lrnr_glm", "Lrnr_earth"),
#cat_method = c("Lrnr_mean", "Lrnr_glmnet")
)
a_misl_imputations
?misl
load_all()
?misl
library('misl')
?misl
?misl
load_all(0)
load_all()
library('misl')
?miskl
?misl
remove.packages("misl")
load_all()
library('misl')
?misl
build()
build(vignettes = FALSE)
load_all()
library('misl')
?misl
build(vignettes = FALSE)
load_all()
library("misl")
?misl
check()
install.packages("glmnet")
install.packages("glmnet")
install.packages("glmnet")
install.packages("glmnet")
library(devtools)
build()
check()
library("misl")
load_all()
library('devtools')
load_all()
?misl
abalone <- read.csv("~/Desktop/abalone.data", header=FALSE)
View(abalone)
library(data.table)
library(tidyverse)
# load data set and take a peek
abalone_data <- read.csv("~/Desktop/abalone.data", header=FALSE)
# add the column names
colnames(abalone_data) <- c("Sex", "Length", "Diameter", "Height", "Whole_Weight", "Shuck_Weight", "Viscera_Weight", "Shell_Weight", "Rings")
# Cleanup the abaolone data to make available for our simulations
abalone <- abalone_data %>%
mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
select(-c(Rings, Age))
str(abalone)
abalone <- as.tibble(abalone)
str(abalone)
abalone
pwd
getwd()
save(abalone, file = "data-raw/abalone.rdata")
library(data.table)
library(tidyverse)
# load data set and take a peek
abalone_data <- read.csv("~/Desktop/abalone.data", header=FALSE)
abalone <- read.csv("~/Desktop/abalone.data", header=FALSE)
str(abalone)
save(abalone, file = "data-raw/abalone.rdata")
abalone <- load('data-raw/abalone.rdata')
library(data.table)
library(tidyverse)
library(usethis)
# load data set and take a peek
abalone <- read.csv("~/Desktop/abalone.data", header=FALSE)
# add the column names
colnames(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_Weight", "Shuck_Weight", "Viscera_Weight", "Shell_Weight", "Rings")
# Cleanup the abaolone data to make available for our simulations
abalone <- abalone %>%
mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
select(-c(Rings, Age))
abalone <- as_tibble(abalone)
write_csv(abalone, "data-raw/abalone.csv")
usethis::use_data(abalone, overwrite = TRUE, compress = 'xz')
load_all()
library('devtools')
load_all()
library("misl")
?misl
?nhanes
?abalone
colnames(abalone)
str(abalone)
nrow(abalone)
load_all()
?abalone
library("misl")
?abalone
?nhanes
build()
build(vignettes = FALSE)
load_all()
library("misl")
?abalone
document()
load_all()
library("misl")
?abalone
?nhanes
build()
document()
?abalone
document
document()
?abalone
document()
?abalone
library("mice")
?mice::nhanes
document()
?abalone
document()
?abalone
getwd()
