load_all()
load_all()
library(mice)
library(misl)
misl_imp <- misl(misl::nhanes, verbose = TRUE)
misl_imp <- misl(misl::nhanes, quiet = FALSE)
load_all()
misl_imp <- misl(misl::nhanes, quiet = FALSE)
traceplot(misl_imp)
misl_imp_2 <- misl(misl::nhanes, maxit = 5, m = 5, quiet = FALSE, con_method = c("Lrnr_mean", "Lrnr_glm_fast", "Lrnr_earth", "Lrnr_xgboost"), bin_method = c("Lrnr_mean", "Lrnr_glm_fast", "Lrnr_xgboost"), cat_method = c("Lrnr_independent_binomial", "Lrnr_mean"))
traceplot(misl_imp_2)
plot(mice_imp)
mice_imp <- mice(misl::nhanes)
plot(mice_imp)
plot(mice_imp)
traceplot(misl_imp_2)
hist(misl::nhanes$Height)
hist(misl_imp_2[[1]]$datasets$Weight)
hist(mice::complete(mice_imp,1)$Height)
hist(misl::nhanes$Height)
hist(misl_imp_2[[2]]$datasets$Weight)
length(misl_imp_2[[2]]$datasets$Weight)
hist(misl_imp_2[[1]]$datasets$Height)
hist(misl::nhanes$Height)
hist(mice::complete(mice_imp,1)$Height)
load_all()
dataset <- misl::nhanes
missing_columns <- colnames(dataset)[colSums(is.na(dataset))!=0]
missing_columns
colnames(nhanes)
column_order <- colnames(dataset)[colSums(is.na(dataset))!=0]
column_order
load_all
load_all()
dataset <- misl::nhanes
m = 5
maxit = 5
seed = NA
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glm")
cat_method = c("Lrnr_mean")
missing_default = "sample"
quiet <- FALSE
m_loop <- 1
# Initialize the return object (or, the dataframes that we want to return)
imputed_datasets <- vector("list", m)
# Do users want to know which dataset they are imputing?
if(!quiet){print(paste("Imputing dataset:", m_loop))}
# Initializes the trace plot (for inspection of imputations)
trace_plot <- expand.grid(statistic = c("mean", "sd"), value = NA, variable = colnames(dataset), m = m_loop, iteration = seq_along(1:maxit))
# Identifies which columns need to be imputed. According to van Buren, this order does not matter.
# https://stefvanbuuren.name/fimd/sec-algoptions.html
column_order <- colnames(dataset)[colSums(is.na(dataset))!=0]
column_order
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
i_loop <- 1
column <- "Weight"
if(!quiet){print(paste("Imputing iteration:", i_loop))}
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing.
# This is our y_dot_obs and x_dot_obs
# https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:normboot
full_dataframe <- dataset_master_copy[!is.na(dataset[[column]]), ]
nrow(full_dataframe)
nrow(dataset)
# Here, we need to fill in the remaining empty cells and we do this with random sampling.
# This is step 2 of https://stefvanbuuren.name/fimd/sec-FCS.html#def:mice
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
nrow(full_dataframe)
View(full_dataframe)
# To avoid complications with variance estimates of the ensemble, we will use bootstrapping
# See note below algorithm: https://stefvanbuuren.name/fimd/sec-pmm.html#def:pmm
# We can also see the following: https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:normboot
bootstrap_sample <- sample_n(full_dataframe, size = nrow(full_dataframe), replace = TRUE)
nrow(bootstrap_sample)
View(bootstrap_sample)
# Next identify the predictors (xvars) and outcome (yvar) depending on the column imputing
xvars <- colnames(bootstrap_sample[ , -which(names(bootstrap_sample) %in% c(column)), drop = FALSE])
yvar <- column
# Specifying the outcome_type will be helpful for checking learners.
outcome_type <- check_datatype(dataset[[yvar]])
outcome_type
# First, define the task using our bootstrap_sample (this helps with variability in imputations)
sl3_task <- sl3::make_sl3_Task(bootstrap_sample, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
# We can then go ahead and train our model
sl_train <- sl3::delayed_learner_train(sl, sl3_task)
# This bit of code can be used if people wanted multi-threading (depending on computer capacity)
sl_sched <- delayed::Scheduler$new(sl_train, delayed::FutureJob, verbose = FALSE)
sl_stack_fit <- sl_sched$compute()
# We are now at the point where we can obtain predictions for matching candidates using X_miss
# We are only interested in those values for which our [[column]] is missing, but we can make predictions on the entire dataset, that's OK!
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# If this is the first iteration then we're going to have missing values for some of our rows.
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <- impute_placeholders(dataset, column_number, missing_default)
}
nrow(dataset_copy)
View(dataset_master_copy)
View(dataset_copy)
# Here we can create the predictions and then we can match them with the hot-deck method
# Interestingly, there are 4 different ways we can match: https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# But, we're going to follow the bootstrap matching method: https://stefvanbuuren.name/fimd/sec-cart.html#sec:cartoverview
# Which is interesting becuase it looks like our beta hat and beta dot are one in the same: https://stefvanbuuren.name/fimd/sec-categorical.html
predictions_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- sl_stack_fit$predict(predictions_task)
# If continuous, we can do matching
# Find the 5 closest donors and making a random draw from them
list_of_matches <- c()
predictions
nrow(predictions)
length(predictions)
hist(predictions)
hist(misl::nhanes$Weight)
column
predictions
View(dataset_copy)
hist(dataset_copy$Weight)
yvar
covariates
xvar
xvars
sl_stack_fit
predictions_task
hist(misl::nhanes$Height)
hist(predictions)
column
hist(misl::nhanes$Weight)
hist(predictions)
column
value <- predictions[1]
value
matches <- Hmisc::find.matches(x = predictions[value], y = ifelse(is.na(dataset[[column]]), NA, dataset[[column]]), maxmatch = 5, tol = 10000)
matches
View(ifelse(is.na(dataset[[column]]), NA, dataset[[column]]))
View(dataset[[column]])
matches
list_of_matches[value] <- dataset[[column]][sample(matches$matches)[1]]
list_of_matches
seq_along(predictions)
length(seq_along(predictions))
nrow(nhanes)
value <- [1]
value <- 1
predictions[value]
matches <- Hmisc::find.matches(x = predictions[value], y = ifelse(is.na(dataset[[column]]), NA, dataset[[column]]), maxmatch = 5, tol = 10000)
matches
# If continuous, we can do matching
# Find the 5 closest donors and making a random draw from them
list_of_matches <- c()
list_of_matches[value] <- dataset[[column]][sample(matches$matches)[1]]
list_of_matches
# If continuous, we can do matching
# Find the 5 closest donors and making a random draw from them
list_of_matches <- c()
for(value in seq_along(predictions)){
matches <- Hmisc::find.matches(x = predictions[value], y = ifelse(is.na(dataset[[column]]), NA, dataset[[column]]), maxmatch = 5, tol = 10000)
list_of_matches[value] <- dataset[[column]][sample(matches$matches)[1]]
}
list_of_matches
length(list_of_matches)
dataset_master_copy[[column]]<- ifelse(is.na(dataset[[column]]), list_of_matches, dataset[[column]])
View(dataset_master_copy)
View(dataset)
column
mean(dataset_master_copy[[column]][is.na(dataset[[column]])])
is.na(dataset[[column]])
View(dataset_master_copy[[column]][is.na(dataset[[column]])])
hist(dataset_master_copy[[column]][is.na(dataset[[column]])])
mean(dataset_master_copy[[column]][is.na(dataset[[column]])])
?nhanes
hist(nhanes$Age)
View(dataset)
View(misl::dataset)
View(misl::nhanes)
# Append to the trace plot only if a numeric column
if(outcome_type != "categorical" & sum(is.na(dataset[[column]])) > 0){
trace_plot$value[trace_plot$variable == column & trace_plot$m == m_loop & trace_plot$iteration == i_loop & trace_plot$statistic == "mean"] <- mean(dataset_master_copy[[column]][is.na(dataset[[column]])])
trace_plot$value[trace_plot$variable == column & trace_plot$m == m_loop & trace_plot$iteration == i_loop & trace_plot$statistic == "sd"] <- sd(dataset_master_copy[[column]][is.na(dataset[[column]])])
}
column_order
column <- "Height"
colSUms(is.na(dataset_master_copy))
colSums(is.na(dataset_master_copy))
# First, we extract all complete records with respect to the column we are imputing.
# This is our y_dot_obs and x_dot_obs
# https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:normboot
full_dataframe <- dataset_master_copy[!is.na(dataset[[column]]), ]
# Here, we need to fill in the remaining empty cells and we do this with random sampling.
# This is step 2 of https://stefvanbuuren.name/fimd/sec-FCS.html#def:mice
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
# To avoid complications with variance estimates of the ensemble, we will use bootstrapping
# See note below algorithm: https://stefvanbuuren.name/fimd/sec-pmm.html#def:pmm
# We can also see the following: https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:normboot
bootstrap_sample <- sample_n(full_dataframe, size = nrow(full_dataframe), replace = TRUE)
# Next identify the predictors (xvars) and outcome (yvar) depending on the column imputing
xvars <- colnames(bootstrap_sample[ , -which(names(bootstrap_sample) %in% c(column)), drop = FALSE])
yvar <- column
# Specifying the outcome_type will be helpful for checking learners.
outcome_type <- check_datatype(dataset[[yvar]])
# First, define the task using our bootstrap_sample (this helps with variability in imputations)
sl3_task <- sl3::make_sl3_Task(bootstrap_sample, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
# We can then go ahead and train our model
sl_train <- sl3::delayed_learner_train(sl, sl3_task)
# This bit of code can be used if people wanted multi-threading (depending on computer capacity)
sl_sched <- delayed::Scheduler$new(sl_train, delayed::FutureJob, verbose = FALSE)
sl_stack_fit <- sl_sched$compute()
# We are now at the point where we can obtain predictions for matching candidates using X_miss
# We are only interested in those values for which our [[column]] is missing, but we can make predictions on the entire dataset, that's OK!
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# If this is the first iteration then we're going to have missing values for some of our rows.
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <- impute_placeholders(dataset, column_number, missing_default)
}
# Here we can create the predictions and then we can match them with the hot-deck method
# Interestingly, there are 4 different ways we can match: https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# But, we're going to follow the bootstrap matching method: https://stefvanbuuren.name/fimd/sec-cart.html#sec:cartoverview
# Which is interesting becuase it looks like our beta hat and beta dot are one in the same: https://stefvanbuuren.name/fimd/sec-categorical.html
predictions_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- sl_stack_fit$predict(predictions_task)
outcome_type
# If continuous, we can do matching
# Find the 5 closest donors and making a random draw from them
list_of_matches <- c()
for(value in seq_along(predictions)){
matches <- Hmisc::find.matches(x = predictions[value], y = ifelse(is.na(dataset[[column]]), NA, dataset[[column]]), maxmatch = 5, tol = 10000)
list_of_matches[value] <- dataset[[column]][sample(matches$matches)[1]]
}
hist(list_of_matches)
column
hist(nhanes$Height)
dataset_master_copy[[column]]<- ifelse(is.na(dataset[[column]]), list_of_matches, dataset[[column]])
mean(dataset_master_copy[[column]][is.na(dataset[[column]])])
View(nhanes)
dataset_master_copy[[column]]<- ifelse(is.na(dataset[[column]]), list_of_matches, dataset[[column]])
column_order
column <- "Education"
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing.
# This is our y_dot_obs and x_dot_obs
# https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:normboot
full_dataframe <- dataset_master_copy[!is.na(dataset[[column]]), ]
# Here, we need to fill in the remaining empty cells and we do this with random sampling.
# This is step 2 of https://stefvanbuuren.name/fimd/sec-FCS.html#def:mice
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
# To avoid complications with variance estimates of the ensemble, we will use bootstrapping
# See note below algorithm: https://stefvanbuuren.name/fimd/sec-pmm.html#def:pmm
# We can also see the following: https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:normboot
bootstrap_sample <- sample_n(full_dataframe, size = nrow(full_dataframe), replace = TRUE)
# Next identify the predictors (xvars) and outcome (yvar) depending on the column imputing
xvars <- colnames(bootstrap_sample[ , -which(names(bootstrap_sample) %in% c(column)), drop = FALSE])
yvar <- column
outcome_type <- check_datatype(dataset[[yvar]])
# First, define the task using our bootstrap_sample (this helps with variability in imputations)
sl3_task <- sl3::make_sl3_Task(bootstrap_sample, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learners
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
# We can then go ahead and train our model
sl_train <- sl3::delayed_learner_train(sl, sl3_task)
# This bit of code can be used if people wanted multi-threading (depending on computer capacity)
sl_sched <- delayed::Scheduler$new(sl_train, delayed::FutureJob, verbose = FALSE)
sl_stack_fit <- sl_sched$compute()
# We are now at the point where we can obtain predictions for matching candidates using X_miss
# We are only interested in those values for which our [[column]] is missing, but we can make predictions on the entire dataset, that's OK!
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# If this is the first iteration then we're going to have missing values for some of our rows.
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <- impute_placeholders(dataset, column_number, missing_default)
}
# Here we can create the predictions and then we can match them with the hot-deck method
# Interestingly, there are 4 different ways we can match: https://stefvanbuuren.name/fimd/sec-pmm.html#sec:pmmcomputation
# But, we're going to follow the bootstrap matching method: https://stefvanbuuren.name/fimd/sec-cart.html#sec:cartoverview
# Which is interesting becuase it looks like our beta hat and beta dot are one in the same: https://stefvanbuuren.name/fimd/sec-categorical.html
predictions_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- sl_stack_fit$predict(predictions_task)
# Here we can begin selection from a canidate donor
# Note, this is unclear... becuase we are using a technique like CART but we don't have terminal nodes.
# But also PMM didn't distinguish how one matches when using bootstrap?
# So, we're not going to be matching with binary or categorical variables, we can just use sampling from their distribution.
# https://stefvanbuuren.name/fimd/sec-categorical.html
predicted_values <- as.character(impute_mode(dataset[[column]]))
predicted_values
as.character(sample(dataset[[column]], 1))
predicted_values <- as.character(sample(dataset[[column]], 1))
predicted_values
dataset_master_copy[[column]] <-  factor(ifelse(is.na(dataset[[column]]), predicted_values, as.character(dataset[[column]])), levels = levels(dataset[[column]]))
View(dataset_master_copy)
table(dataset_master_copy$Education)
predicted_values
load_all()
library(mice)
misl_imp_2 <- misl(misl::nhanes, maxit = 5, m = 5, quiet = FALSE)
traceplot(misl_imp_2)
misl_imp <- misl(misl::nhanes, maxit = 5, m = 4, quiet = FALSE,
con_method = c("Lrnr_mean", "Lrnr_glm_fast", "Lrnr_earth", "Lrnr_glmnet", "Lrnr_polspline"),
bin_method = c("Lrnr_mean", "Lrnr_earth", "Lrnr_glm_fast"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_mean"))
traceplot(misl_imp)
misl_modeling <- lapply(misl_imp, function(y){
stats::lm(TotChol ~ Age + Weight + Height + Smoke100 + Education, data = y$datasets)
})
summary(mice::pool(misl_modeling), conf.int = TRUE)
mice_imp <- mice(misl::nhanes)
plot(mice_imp)
traceplot(misl_imp)
View(nhanes)
misl::abalone
library(data.table)
library(tidyverse)
library(usethis)
library(mice)
# load data set and take a peek
abalone <- read.csv("~/Desktop/abalone.data", header=FALSE)
# load data set and take a peek
abalone <- read.csv("~/Desktop/abalone.data", header=FALSE)
# load data set and take a peek
abalone <- read.csv("~/Desktop/abalone.rdata", header=FALSE)
load("/Users/thomascarpenito/Desktop/abalone.rdata")
# add the column names
colnames(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_Weight", "Shuck_Weight", "Viscera_Weight", "Shell_Weight", "Rings")
abalone <- abalone %>%
mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
select(-c(Rings, Age))
# load data set and take a peek
abalone <- read.csv("~/Desktop/abalone.data", header=FALSE)
View(abalone)
load("~/Documents/Programming/misl/data-raw/abalone.rdata")
View(abalone)
# add the column names
colnames(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_Weight", "Shuck_Weight", "Viscera_Weight", "Shell_Weight", "Rings")
View(abalone)
abalone <- abalone %>%
mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
select(-c(Rings, Age))
abalone <- abalone %>%
dplyr::mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
select(-c(Rings, Age))
abalone <- abalone %>%
dplyr::mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
dplyr::select(-c(Rings, Age))
amputed_abalone <- mice::ampute(abalone, mech = "MAR", prop = .50)
View(amputed_abalone)
View(amputed_abalone$amp)
amputed_abalone <- mice::ampute(abalone, mech = "MCAR", prop = .50)
abalone <- as_tibble(amputed_abalone$amp)
str(abalone)
write_csv(abalone, "data-raw/abalone.csv")
usethis::use_data(abalone, overwrite = TRUE, compress = 'xz')
load_all()
View(abalone)
colnames(abalone)
load("~/Documents/Programming/misl/data-raw/abalone.rdata")
set.seed(1234)
# load data set and take a peek
abalone <- read.csv("~/Desktop/abalone.data", header=FALSE)
# add the column names
colnames(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_Weight", "Shuck_Weight", "Viscera_Weight", "Shell_Weight", "Rings")
# Cleanup the abaolone data to make available for our simulations
abalone <- abalone %>%
dplyr::mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
dplyr::select(-c(Rings, Age, Shuck_Weight, Viscera_Weight, Shell_Weight))
load("~/Documents/Programming/misl/data-raw/abalone.rdata")
set.seed(1234)
# add the column names
colnames(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_Weight", "Shuck_Weight", "Viscera_Weight", "Shell_Weight", "Rings")
abalone <- abalone %>%
dplyr::mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
dplyr::select(-c(Rings, Age, Shuck_Weight, Viscera_Weight, Shell_Weight))
colnames(abalone)
mypatterns <- expand.grid(Sex = 0:1, Length = 0:1, Diameter = 0:1, Height = 0:1, Whole_Weight_Pred = 0:1, Older_12 = 0:1,)
mypatterns <- expand.grid(Sex = 0:1, Length = 0:1, Diameter = 0:1, Height = 0:1, Whole_Weight_Pred = 0:1, Older_12 = 0:1)
mypatterns <- mypatterns[sample(1:nrow(mypatterns), replace = FALSE, 8),]
mypatterns <- mypatterns[rowSums(mypatterns) != 0,]
mypatterns
load("~/Documents/Programming/misl/data-raw/abalone.rdata")
set.seed(1234)
# load data set and take a peek
#abalone <- read.csv("~/Desktop/abalone.data", header=FALSE)
# add the column names
colnames(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_Weight", "Shuck_Weight", "Viscera_Weight", "Shell_Weight", "Rings")
# Cleanup the abaolone data to make available for our simulations
abalone <- abalone %>%
dplyr::mutate(Age = Rings + 1.5,
Sex = as.factor(Sex),
Older_12 = as.integer(Age > 12)
) %>%
dplyr::select(-c(Rings, Age, Shuck_Weight, Viscera_Weight, Shell_Weight))
mypatterns <- expand.grid(Sex = 0:1, Length = 0:1, Diameter = 0:1, Height = 0:1, Whole_Weight_Pred = 0:1, Older_12 = 0:1)
mypatterns <- mypatterns[sample(1:nrow(mypatterns), replace = FALSE, 8),]
mypatterns <- mypatterns[rowSums(mypatterns) != 0,]
amputed_abalone <- mice::ampute(abalone, mech = "MCAR", prop = .50)
abalone <- as_tibble(amputed_abalone$amp)
View(abalone)
write_csv(abalone, "data-raw/abalone.csv")
usethis::use_data(abalone, overwrite = TRUE, compress = 'xz')
load_all()
View(misl::abalone)
misl_imp_2 <- misl(misl::abalone, maxit = 5, m = 5, quiet = FALSE)
mice_imp <- mice(misl::abalone)
plot(mice_imp)
misl_imp <- misl(misl::nhanes, maxit = 5, m = 4, quiet = FALSE,
con_method = c("Lrnr_mean", "Lrnr_glm_fast", "Lrnr_earth", "Lrnr_glmnet", "Lrnr_polspline"),
bin_method = c("Lrnr_mean", "Lrnr_earth", "Lrnr_glm_fast"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_mean"))
plan(list(tweak(multisession, workers = 4), sequential))
library(misl)
library(future)
plan(list(tweak(multisession, workers = 4), sequential))
misl_imp <- misl(misl::nhanes, maxit = 5, m = 4, quiet = FALSE,
con_method = c("Lrnr_mean", "Lrnr_glm_fast", "Lrnr_earth", "Lrnr_glmnet", "Lrnr_polspline"),
bin_method = c("Lrnr_mean", "Lrnr_earth", "Lrnr_glm_fast"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_mean"))
traceplot(misl_imp)
plan(list(tweak(multisession, workers = 4), sequential))
misl_imp <- misl(misl::abalone, maxit = 5, m = 4, quiet = FALSE,
con_method = c("Lrnr_mean", "Lrnr_glm_fast", "Lrnr_earth", "Lrnr_glmnet", "Lrnr_polspline"),
bin_method = c("Lrnr_mean", "Lrnr_earth", "Lrnr_glm_fast"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_mean"))
misl_imp
traceplot(misl_imp)
View(misl::abalone)
str(misl::abalone)
misl_imp <- misl(misl::abalone, maxit = 5, m = 4, quiet = FALSE,
con_method = c("Lrnr_mean", "Lrnr_glm_fast", "Lrnr_earth", "Lrnr_glmnet", "Lrnr_polspline"),
bin_method = c("Lrnr_mean", "Lrnr_earth", "Lrnr_glm_fast"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_mean"))
plant(c(sequential, sequential))
plan(c(sequential, sequential))
misl_imp <- misl(misl::abalone, maxit = 5, m = 4, quiet = FALSE,
con_method = c("Lrnr_mean", "Lrnr_glm_fast", "Lrnr_earth", "Lrnr_glmnet", "Lrnr_polspline"),
bin_method = c("Lrnr_mean", "Lrnr_earth", "Lrnr_glm_fast"),
cat_method = c("Lrnr_independent_binomial", "Lrnr_mean"))
traceplot(misl_imp)
misl_modeling <- lapply(misl_imp, function(y){
stats::lm(TotChol ~ Age + Weight + Height + Smoke100 + Education, data = y$datasets)
})
summary(mice::pool(misl_modeling), conf.int = TRUE)
library('devtools')
build(vignettes = FALSE)
