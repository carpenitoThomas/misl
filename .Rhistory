full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
outcome_type <- check_datatype(dataset[[yvar]])
outcome_type
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learner
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(outcome_type == "binary"){
predicted_values <- rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + rnorm(n = length(predictions), mean = 0, sd = sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <- ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]])
}
# We can set this column back in the dataframe and move on to the next.
new_imputed_dataset <- dataset_master_copy
# Lastly, we should remove the learners for the next column (should there be overlap)
for(learner in learner_list){
code.lm <- paste("rm(", learner, ")", sep="")
eval(parse(text=code.lm))
}
column_order
column <- "Education"
# Print what column we are starting with
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- new_imputed_dataset[!is.na(new_imputed_dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
colSums(is.na(full_dataframe))
nrow(full_dataframe)
colSums(is.na(dataset))
7221 + 2779
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
missing_yvar
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
outcome_type <- check_datatype(dataset[[yvar]])
outcome_type
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learner
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
stack_fit$predict(new_prediction_task)
predictions <- stack_fit$predict(new_prediction_task)
predictions
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(outcome_type == "binary"){
predicted_values <- rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + rnorm(n = length(predictions), mean = 0, sd = sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <- ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]])
}
# We can set this column back in the dataframe and move on to the next.
new_imputed_dataset <- dataset_master_copy
new_imputed_dataset
sl3::predict_classes(sl3::unpack_predictions(predictions))
dataset_master_copy[[column]]
dataset_copy
colSusm(is.na(dataset_copy))
colSums(is.na(dataset_copy))
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
new_prediction_task
predictions <- stack_fit$predict(new_prediction_task)
predictions
outcome_type
dataset_master_copy
load_all()
library("misl")
dataset <- nhanes
m = 5
maxit = 5
seed = NA
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glm")
cat_method = c("Lrnr_mean", "Lrnr_glmnet")
missing_default = "mean"
quiet = FALSE
column_order
# Identify which order the columns should be imputed.
# The order here specifies most missing data to least though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
# Create the newly imputed dataset
new_imputed_dataset <- dataset
column_order
column_order[-1]
column_order[1:5]
# Begin the iteration column by column
for(column in column_order[1:5]){
# Print what column we are starting with
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- new_imputed_dataset[!is.na(new_imputed_dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
outcome_type <- check_datatype(dataset[[yvar]])
# We should now have a complete dataframe and can being misl.
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# TODO: Add Screeners?
# Depending on the outcome, we need to build out the learner
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(outcome_type == "binary"){
predicted_values <- rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + rnorm(n = length(predictions), mean = 0, sd = sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <- ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]])
}
# We can set this column back in the dataframe and move on to the next.
new_imputed_dataset <- dataset_master_copy
# Lastly, we should remove the learners for the next column (should there be overlap)
for(learner in learner_list){
code.lm <- paste("rm(", learner, ")", sep="")
eval(parse(text=code.lm))
}
}
i <- 1
# Begin the iteration column by column
for(column in column_order[1:5]){
# Print what column we are starting with
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- new_imputed_dataset[!is.na(new_imputed_dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
outcome_type <- check_datatype(dataset[[yvar]])
# We should now have a complete dataframe and can being misl.
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# TODO: Add Screeners?
# Depending on the outcome, we need to build out the learner
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
if(column_type == "categorical"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(column_type == "binary"){
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  get(missing_default)(dataset_copy[[column_number]], na.rm = TRUE)
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(outcome_type == "binary"){
predicted_values <- rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(outcome_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + rnorm(n = length(predictions), mean = 0, sd = sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <- ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]])
}
# We can set this column back in the dataframe and move on to the next.
new_imputed_dataset <- dataset_master_copy
# Lastly, we should remove the learners for the next column (should there be overlap)
for(learner in learner_list){
code.lm <- paste("rm(", learner, ")", sep="")
eval(parse(text=code.lm))
}
}
column_order
column <- "Education"
str(new_imputed_dataset)
colSums(is.na(new_imputed_dataset))
# Do users want to know which iteration they are imputing?
if(!quiet){print(paste("Imputing iteration:", i))}
# Print what column we are starting with
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- new_imputed_dataset[!is.na(new_imputed_dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
str(full_dataframe)
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
yvar
xvars
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
missing_yvar
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[[column_number]]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
full_dataframe
outcome_type <- check_datatype(dataset[[yvar]])
outcome_type
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learner
learners <- switch(outcome_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(sl3::Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- sl3::Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
dataset_master_copy
dataset_copy <- dataset_master_copy
column_number
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
column_type <- check_datatype(dataset[[column_number]])
column_type
dataset_copy[is.na(dataset_copy[[column_number]]), column_number]
impute_mode(dataset_copy[[column_number]])
dataset_copy[is.na(dataset_copy[[column_number]]), column_number] <-  impute_mode(dataset_copy[[column_number]])
dataset_copy
colSusm(is.na(dataset_copy))
colSums(is.na(dataset_copy))
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
predictions
outcome_type
ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]])
sl3::predict_classes(sl3::unpack_predictions(predictions))
missing_yvar
ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]])
dataset[[column]]
sl3::predict_classes(sl3::unpack_predictions(predictions))
str(sl3::predict_classes(sl3::unpack_predictions(predictions)))
ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]])
str(ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]]))
missing_yvar
as.character(ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]]))
ifelse(missing_yvar, sl3::predict_classes(sl3::unpack_predictions(predictions)), dataset[[column]])
?ifelse
ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]]))
str(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]] <-  as.factor(ifelse(missing_yvar, as.character(sl3::predict_classes(sl3::unpack_predictions(predictions))), as.character(dataset[[column]])))
dataset_master_copy
str(dataset_master_copy)
load_all()
dataset <- nhanes
library(misl)
misl_imp <- misl(nhanes, maxit = 2, m = 2)
build_rmd()
colnames(nhanes)
build_rmd()
build_all()
load_all()
build_rmd()
build_readme()
nhanes
library(misl)
misl_imp <- misl(nhanes, maxit = 2, m = 2, quiet = TRUE)
misl_imp
misl_modeling <- lapply(misl_imp, function(y){
stats::lm(TotChol ~ Age + Weight + Height + Smoke100 + Education, data = y)
})
summary(mice::pool(misl_modeling))
build_readme()
