misl <- function(dataset,
m = 5,
maxit = 5,
seed = NA,
con_method = c("Lrnr_mean", "Lrnr_glm"),
bin_method = c("Lrnr_mean", "Lrnr_glmnet"),
cat_method = c("Lrnr_mean", "Lrnr_glmnet"),
missing_default = "mean",
quiet = TRUE
){
# TO ADD: checks that we can actually begin the MISL algorithm.
# Initialize the return object (or, the dataframes that we want to return)
imputed_datasets <- vector("list", m)
# This loop defines each of the imputed m datasets.
for(m_loop in seq_along(1:m)){
# Do users want to know which dataset they are imputing?
if(!quiet){print(paste("Imputing dataset:", m_loop))}
# Identify which order the columns should be imputed.
# The order here specifies most missing data to least though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
# Next, we begin the iterations within each dataset.
for(i in seq_along(1:maxit)){
# Do users want to know which iteration they are imputing?
if(!quiet){print(paste("Imputing iteration:", i))}
# Begin the iteration column by column
for(column in column_order){
# Print what column we are starting with
if(!quiet){print(paste("Imputing:", column))}
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset[!is.na(dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
column_type <- NULL
for(column_number in seq_along(full_dataframe)){
full_dataframe[,column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
column_type <- "continuous"
# We should now have a complete dataframe and can being misl.
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# TODO: Add Screeners?
# Depending on the outcome, we need to build out the learner
learners <- switch(column_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- ", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- make_learner(Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
if(class(dataset_copy[[column_number]]) == "factor"){
dataset_copy[is.na(dataset_copy[,column_number]), column_number] <-  impute_mode(dataset_copy[,column_number])
column_type <- "categorical"
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(length(levels(as.factor(dataset_copy[,column_number]))) == 2){
dataset_copy[is.na(dataset_copy[,column_number]), column_number] <-  impute_mode(dataset_copy[,column_number])
column_type <- "binary"
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[,column_number]), column_number] <-  get(missing_default)(dataset_copy[,column_number], na.rm = TRUE)
column_type <- "continuous"
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(column_type == "binary"){
predicted_values <- rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(column_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + rnorm(n = length(predictions), mean = 0, sd = sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions, dataset[[column]])
}
# We can set this column back in the dataframe and move on to the next.
new_imputed_dataset <- dataset_master_copy
# Lastly, we should remove the learners for the next column (should there be overlap)
for(learner in learner_list){
code.lm <- paste("rm(", learner, ")", sep="")
eval(parse(text=code.lm))
}
}
}
# After all columns are imputed, we can save the dataset for recall later
imputed_datasets[[m_loop]] <- new_imputed_dataset
}
return(imputed_datasets)
}
m = 5
maxit = 5
seed = NA
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glmnet")
cat_method = c("Lrnr_mean", "Lrnr_glmnet")
missing_default = "mean"
quiet <- FALSE
dataset
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
# Identify which order the columns should be imputed.
# The order here specifies most missing data to least though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
misl(nhanes, quiet = FALSE)
column <- "age"
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset[!is.na(dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
i <- 1
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset[!is.na(dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
column_type <- NULL
for(column_number in seq_along(full_dataframe)){
full_dataframe[,column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
column_type <- "continuous"
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
impute_placeholders(full_dataframe, column_number, missing_default)
full_dataframe
dataset
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset[!is.na(dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
full_dataframe
full_dataframe
column_number
missing_default
class(dataset[[column_number]])
get(missing_default)(dataset[,column_number], na.rm = TRUE)
dataset[is.na(dataset[,column_number]), column_number] <-  get(missing_default)(dataset[,column_number], na.rm = TRUE)
dataset[is.na(dataset[,column_number]), column_number]
dataset
dataset[is.na(dataset[,column_number]), column_number]
full_dataframe
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[,column_number]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
full_dataframe[is.na(full_dataframe[,column_number]), column_number]
column_number
full_dataframe
impute_placeholders(full_dataframe, column_number, missing_default)
full_dataframe
column_number
missing_default
class(dataset[[column_number]])
get(missing_default)(dataset[,column_number], na.rm = TRUE)
impute_placeholders <- function(dataset, column_number, missing_default){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
if(class(dataset[[column_number]]) == "factor"){
impute_mode(dataset[,column_number])
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(length(levels(as.factor(dataset[,column_number]))) == 2){
impute_mode(dataset[,column_number])
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
get(missing_default)(dataset[,column_number], na.rm = TRUE)
}
}
}
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[,column_number]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
full_dataframe
library('devtools')
build()
library("misl")
?misl
misl(nhanes)
library("mice")
mis(nhanes)
misl(nhanes, quiet = FALSE)
library("sl3")
misl(nhanes, quiet = FALSE)
dataset <- nhanes
m = 5
maxit = 5
con_method = c("Lrnr_mean", "Lrnr_glm")
bin_method = c("Lrnr_mean", "Lrnr_glmnet")
cat_method = c("Lrnr_mean", "Lrnr_glmnet")
missing_default = "mean"
i <- 1
column <- "age"
# Identify which order the columns should be imputed.
# The order here specifies most missing data to least though the order should not be important (per MICE).
column_order <- colnames(dataset)[order(colSums(is.na(dataset)))]
# Retain a copy of the dataset for each of the new m datasets
dataset_master_copy <- dataset
# First, we extract all complete records with respect to the column we are imputing
# Note, with the second iteration we should be using *all* rows of our dataframe (since the missing values were imputed on the first iteration)
if(i == 1){
# For the first iteration, we're using only those rows for which data exists for the variable
full_dataframe <- dataset[!is.na(dataset[[column]]), ]
}else{
# After the first iteration, we can use the newly imputed dataset (which should be full)
full_dataframe <- new_imputed_dataset
}
full_dataframe
# Next identify the predictors (x vars) and outcome (y var) depending on the column imputing
yvar <- column
xvars <- colnames(full_dataframe[ , -which(names(full_dataframe) %in% c(column)), drop = FALSE])
yvar
xvars
# We need to keep track of which values from the original dataframe are missing
# This is important becuase after the first iteration NONE of the values will be classified as missing
# Since MISL will have imputed them. When we iterate we only want to change these values per column.
missing_yvar <- is.na(dataset[[column]])
missing_yvar
# For the first iteration, any missing values will need to be set to either the mean or mode of the column.
# This will also serve as a "catch" if the algorithm chooses not to impute values for this column as well upon successive iterations.
# Note, we include the "yvar" in this iteration though nothing should be imputed for this column (since we subsetted with respect to it being full)
# It would be easy to define this column type as a variable.
column_type <- NULL
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[,column_number]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
load()
load
load_all()
for(column_number in seq_along(full_dataframe)){
full_dataframe[is.na(full_dataframe[,column_number]), column_number] <-  impute_placeholders(full_dataframe, column_number, missing_default)
}
full_dataframe
column_type <- "continuous"
# First, define the task
task <- sl3::make_sl3_Task(full_dataframe, covariates = xvars, outcome = yvar)
# Depending on the outcome, we need to build out the learner
learners <- switch(column_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- ", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- make_learner(Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
# Then we make and train the Super Learner
sl <- Lrnr_sl$new(learners = stack)
stack_fit <- sl$train(task)
# And finally obtain predictions from the stack on the full dataframe
if(i == 1){
dataset_copy <- dataset_master_copy
for(column_number in seq_along(dataset_copy)){
# This is a check to see if the column is a factor, requiring mode imputation
# This means that the column should be registered as a factor.
if(class(dataset_copy[[column_number]]) == "factor"){
dataset_copy[is.na(dataset_copy[,column_number]), column_number] <-  impute_mode(dataset_copy[,column_number])
column_type <- "categorical"
}else{
# We assume now that we have some continuous variable... BUT this variable could be binary or continuous
# Major assumption, if the column is binary then it must ONLY have the values 0,1 (not 1,2 - for example)
# This function is incomplete in its checks...
if(length(levels(as.factor(dataset_copy[,column_number]))) == 2){
dataset_copy[is.na(dataset_copy[,column_number]), column_number] <-  impute_mode(dataset_copy[,column_number])
column_type <- "binary"
}else{
# Here, we assume a continuous variable and can use simple mean or median imputation
dataset_copy[is.na(dataset_copy[,column_number]), column_number] <-  get(missing_default)(dataset_copy[,column_number], na.rm = TRUE)
column_type <- "continuous"
}
}
}
}else{
dataset_copy <- full_dataframe
}
new_prediction_task <- sl3::sl3_Task$new(dataset_copy, covariates = xvars, outcome = yvar)
predictions <- stack_fit$predict(new_prediction_task)
# Once we have the predictions we can replace the missing values from the original dataframe
# Note, we add a bit of random noise here
if(column_type == "binary"){
predicted_values <- rbinom(length(dataset_master_copy[[column]]), 1, predictions)
dataset_master_copy[[column]] <- ifelse(missing_yvar, predicted_values, dataset[[column]])
}else if(column_type == "continuous"){
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions + rnorm(n = length(predictions), mean = 0, sd = sd(predictions) ), dataset[[column]])
}else{
# In this instance, the column type is categorical
# This is depedent on what the super learner returns (predictions or predicted probabilities)
dataset_master_copy[[column]]<- ifelse(missing_yvar, predictions, dataset[[column]])
}
library(devtools)
load_all()
?misl
library('mice')
misl(nhanes)
library("sl3")
misl(nhanes)
library('devtools')
load_all()
library("moce")
library("mioce")
library("mice")
misl(nhanes)
sl3::make_learner(Stack)
library("sl3")
misl(nhanes, quiet = FALSE)
use_package("sl3")
library("devtools")
library("mice")
load_all()
misl(nhanes, quiet = FALSE)
sl3::make_learner(Stack)
load_all()
misl(nhanes, quiet = FALSE)
paste("stack", " <- sl3::make_learner(Stack,",paste(learner_list, collapse = ", "), ")", sep="")
con_method = c("Lrnr_mean", "Lrnr_glm")
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Depending on the outcome, we need to build out the learner
learners <- switch(column_type,
categorical = cat_method,
binary = bin_method ,
continuous = con_method)
learners <- con_method
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(Stack,",paste(learner_list, collapse = ", "), ")", sep="")
learner_stack_code
code.lm
# Next, iterate through each of the supplied learners to build the SL3 learner list
learner_list <- c()
for(learner in learners){
code.lm <- paste(learner, " <- sl3::", learner, "$new()", sep="")
eval(parse(text=code.lm))
learner_list <- c(learner, learner_list)
}
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
learner_stack_code
library("sl3")
# Next we stack the learners
learner_stack_code <- paste("stack", " <- sl3::make_learner(Stack,",paste(learner_list, collapse = ", "), ")", sep="")
eval(parse(text=learner_stack_code))
library("devtools")
library("mice")
load_all()
misl(nhanes, quiet = FALSE)
load_all()
misl(nhanes, quiet = FALSE)
?mice
imp <- mice(nhanes)
?oldClass()
imp$data
complete(imp)
complete(imp,2)
View(imp)
?complete
complete(imp,1)
View(complete(imp,1))
View(imp$imp$bmi)
View(nhanes)
sum(is.na(nhanes$bmi))
complete(nhanes)
?complete
?with
?pool
misl_test <- misl(nhanes)
fit <- with(data = misl_test, exp = lm(bmi ~ hyp + chl))
imp <- mice(nhanes, maxit = 2, m = 2)
fit <- with(data = imp, exp = lm(bmi ~ hyp + chl))
?with
with(data = misl_test, exp = lm(bmi ~ hyp + chl))
misl_test
with(misl_test, {
boxplot(bmi ~ age)})
str(misl_test)
within(data = misl_test, exp = lm(bmi ~ hyp + chl))
imp
View(misl_test)
with(data = misl_test , expr = lm(bmi ~ hyp + chl))
?with
misl_test[[1]]
with(data = misl_test[[1]] , expr = lm(bmi ~ hyp + chl))
testing <- with(data = im, exp = lm(bmi ~ hyp + chl))
testing <- with(data = imp, exp = lm(bmi ~ hyp + chl))
testing
paste0(y, " ~ X")
testing2 <- lapply(misl_test, function(){
lm(bmi ~ hyp + chl)
})
testing2 <- lapply(misl_test, function(y){
print(y)
lm(bmi ~ hyp + chl)
})
testing2 <- lapply(misl_test, function(y){
print(y)
lm(bmi ~ hyp + chl, data = y)
})
testing2 <- lapply(misl_test, function(y){
lm(bmi ~ hyp + chl, data = y)
})
testing2
summary(pool(testing))
summary(pool(testing2))
?mice
?complete
?pool
imp <- mice(nhanes, maxit = 2, m = 2)
testing <- with(data = imp, exp = lm(bmi ~ hyp + chl))
misl_imp <- misl(nhanes, maxit = 2, m = 2, quiet = FALSE)
misl_modeling <- lapply(misl_test, function(y){
lm(bmi ~ hyp + chl, data = y)
})
summary(pool(mice_modeling))
mice_modeling <- with(data = imp, exp = lm(bmi ~ hyp + chl))
misl_modeling <- lapply(misl_test, function(y){
lm(bmi ~ hyp + chl, data = y)
})
summary(pool(misl_modeling))
summary(pool(mice_modeling))
build_rmd()
test()
build()
check()
mice::nhanes
?lm
build_rmd()
build_readme()
build_readme()
git status
